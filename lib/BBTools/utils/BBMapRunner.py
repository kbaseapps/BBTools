from __future__ import print_function
import os
import time
import uuid
import zipfile
from pprint import pprint

from BBTools.utils.BBToolsRunner import BBToolsRunner
from installed_clients.KBaseReportClient import KBaseReport
from commandbuilder import build_options
from .file_util import (
    download_assemblies,
    download_assembly,
    download_interleaved_reads,
    upload_interleaved_reads,
    pack_and_upload_folder,
    mkdir_p
)


class BBMapRunner:

    BBMAP_CMD = 'bbmap.sh'

    def __init__(self, callback_url, scratch_dir):
        self.callback_url = callback_url
        self.scratch_dir = scratch_dir
        self._timestamp = str(int(time.time() * 1000))  # used for output and report directory names.
        has_kb_data = os.path.isdir("/kb/data")
        has_data = os.path.isdir("/data")
        has_kb = os.path.isdir("/kb")

        print("/kb/data - {}".format(has_kb_data))
        try:
            print(os.listdir("/kb/data"))
        except:
            print("can't list dir /kb/data")
        print("/data - {}".format(has_data))
        try:
            print(os.listdir("/data"))
        except:
            print("can't list dir /data")
        print("/kb - {}".format(has_kb))
        try:
            print(os.listdir("/kb"))
        except:
            print("can't list dir /kb")

    def run_app(self, io_params, app_params):
        output_dir, run_log, run_command = self._run(io_params, app_params, is_app=True)
        return self._save_output_to_kbase(io_params, app_params, output_dir, run_log, run_command)

    def run_local(self, io_params, app_params):
        output_dir, run_log, run_command = self._run(io_params, app_params, is_app=False)
        file_lookup = self._read_outputfile(os.path.join(output_dir, 'file-list.txt'))
        file_lookup2 = self._read_outputdir(output_dir)
        for k in file_lookup2.keys():
            file_lookup[k] = file_lookup2[k]
        result = {
            'output_directory': output_dir,
            'run_log': run_log,
            'mapped_reads_paths': None,
            'unmapped_reads_paths': None,
            'bam_paths': None,
            'coverage_paths': None,
            'run_command': run_command
        }
        output_created = False
        if 'mapped_reads_files' in file_lookup:
            result['mapped_reads_paths'] = []
            for file_name in file_lookup['mapped_reads_files'].split(','):
                result['mapped_reads_paths'].append(os.path.join(output_dir, file_name))
            output_created = True
        if 'unmapped_reads_files' in file_lookup:
            result['unmapped_reads_paths'] = []
            for file_name in file_lookup['unmapped_reads_files'].split(','):
                result['unmapped_reads_paths'].append(os.path.join(output_dir, file_name))
            output_created = True
        if 'bam_files' in file_lookup:
            result['bam_paths'] = []
            for file_name in file_lookup['bam_files'].split(','):
                result['bam_paths'].append(os.path.join(output_dir, file_name))
            output_created = True
        if 'coverage_files' in file_lookup:
            result['coverage_paths'] = []
            for file_name in file_lookup['coverage_files'].split(','):
                result['coverage_paths'].append(os.path.join(output_dir, file_name))
            output_created = True
        if not output_created:
            print('No output generated by BBTools BBMap!')
        return result

    def _run(self, io_params, app_params, is_app=True):
        """
        Does the run part of BBMap. Formats parameters, etc., then sends them off
        to the BBToolsRunner to run.
        At the end, returns the output directory, path to the run log, and the command-line string
        that was run.
        """
        print('Running BBMap. Params=')
        pprint(io_params)
        pprint(app_params)
        self._runtime = str(int(time.time() * 1000))
        output_dir = os.path.join(self.scratch_dir, 'bbmap_output_' + self._timestamp)
        run_log = os.path.join(output_dir, 'run_log.txt')
        options = self._process_app_params_to_cli(io_params, app_params, output_dir, run_log, is_app)
        bbtools = BBToolsRunner(self.scratch_dir)
        bbtools.run(self.BBMAP_CMD, options, log_path=run_log)
        cmd = [self.BBMAP_CMD] + options
        self._create_output_file_list('file-list.txt', output_dir)
        return output_dir, run_log, " ".join(cmd)

    def _create_output_file_list(self, file_list_name, output_dir):
        file_list_path = os.path.join(output_dir, file_list_name)
        mapped_reads_files = []
        unmapped_reads_files = []
        bam_files = []
        
        for name in os.listdir(output_dir):
            if name.endswith('.FASTQ'):
                if name.endswith('-UNMAPPED.FASTQ'):
                    unmapped_reads_files.append(name)
                elif name.endswith('-MAPPED.FASTQ'):
                    mapped_reads_files.append(name)
                else:
                    raise ValueError ("unknown file "+name+" was created as output")
            elif name.endswith('.BAM'):
                bam_files.append(name)

        with open (file_list_path, 'w') as file_list_handle:
            if len(mapped_reads_files) > 0:
                this_line = 'mapped_reads_files'+"\t"+','.join(mapped_reads_files)+"\n"
                file_list_handle.write(this_line)
            if len(unmapped_reads_files) > 0:
                this_line = 'unmapped_reads_files'+"\t"+','.join(unmapped_reads_files)+"\n"
                file_list_handle.write(this_line)
            if len(bam_files) > 0:
                this_line = 'bam_files'+"\t"+','.join(bam_files)+"\n"
                file_list_handle.write(this_line)

        return file_list_path


    def _process_app_params_to_cli(self, io_params, app_params, output_dir, run_log, is_app):
        ''' given the parameters passed into the KBase App, validate them, stage the input
            and create the set of options that will be passed to rqcfilter.sh '''

        available_params = {
            'input_parameter_suite': {'type': 'string'},
            'speed_mode': {'type': 'string',
                           'allowed_values': ['vslow', 'slow', 'default', 'fast']},
            'min_id': {'type': 'float'},
            'kmer_len': {'type': 'int'},
            'max_indel': {'type': 'int'},
            'strict_max_indel': {'type': 'boolean'},
            'subfilter_thresh': {'type': 'int'},
            'delfilter_thresh': {'type': 'int'},
            'require_correct_strand': {'type': 'boolean'},
            'qual_score_mode': {'type': 'string',
                                'allowed_values': ['33', '64']}
        }

        self._validate_file_inputs(io_params, is_app)
        if 'in_assembly_refs' in io_params:
            assembly_files = download_assemblies(
                self.callback_url, io_params['in_assembly_refs'])
        else:
            assembly_files = io_params['in_assembly_paths']
        if 'in_readslib_ref' in io_params:
            reads_file = download_interleaved_reads(
                self.callback_url, io_params['in_readslib_ref'])['files']['fwd']
        else:
            reads_file = io_params['in_readslib_path']

        # maxmem is brought in, possibly as well.
        # it should be removed from the build options list, as it's a special
        # command sent to java to set memory requirements
        #mem = 50
        mem = 15
        if 'maxmem' in app_params:
            try:
                mem = int(app_params['maxmem'])
                if mem < 1:
                    raise ValueError()
                del app_params['maxmem']
            except:
                raise ValueError('The value of maxmem must be an integer > 0.')

        # run BBMap separately for each assembly file target
        # (enable multi later)
        options = []
        for (assembly_i, assembly_file) in enumerate(assembly_files):
            # acting as validator, but not returning values
            #options = build_options(app_params, available_params)
            build_options(app_params, available_params)
            
            # setup input/output paths
            options.append('ref={}'.format(assembly_file))
            options.append('nodisk')
            options.append('in={}'.format(reads_file))

            mkdir_p(output_dir)
            if app_params.get('get_bam') and int(app_params['get_bam']) != 0:
                bam_out_file = os.path.join(output_dir, str(assembly_i)+'-'+io_params['out_obj_name']+'.BAM')
                options.append('out={}'.format(bam_out_file))
            if app_params.get('get_mapped_reads') and int(app_params['get_mapped_reads']) != 0:
                mapped_reads_out_file = os.path.join(output_dir, str(assembly_i)+'-'+io_params['out_obj_name']+'-'+'MAPPED'+'.FASTQ')
                options.append('outm={}'.format(mapped_reads_out_file))
            if app_params.get('get_unmapped_reads') and int(app_params['get_unmapped_reads']) != 0:
                unmapped_reads_out_file = os.path.join(output_dir, str(assembly_i)+'-'+io_params['out_obj_name']+'-'+'UNMAPPED'+'.FASTQ')
                options.append('outu={}'.format(unmapped_reads_out_file))

            # add user-config params
            if app_params.get('input_parameter_suite'):
                options.append(app_params['input_parameter_suite'])

            if app_params.get('kmer_len') and int(app_params['kmer_len']) != 0:
                if not app_params.get('input_parameter_suite') \
                   or 'k=' not in app_params.get('input_parameter_suite'):
                    options.append("k={}".format(str(app_params['kmer_len'])))

            if app_params.get('max_indel'):
                if not app_params.get('input_parameter_suite') \
                   or 'maxindel=' not in app_params.get('input_parameter_suite'):
                    options.append("maxindel={}".format(str(app_params['max_indel'])))

            if app_params.get('strict_max_indel') and int(app_params['strict_max_indel']) != 0:
                if not app_params.get('input_parameter_suite') \
                   or 'strictmaxindel' not in app_params.get('input_parameter_suite'):
                    options.append("strictmaxindel")

            if app_params.get('require_correct_strand'):
                if int(app_params['require_correct_strand']) != 0:
                    if not app_params.get('input_parameter_suite') \
                       or 'rcs=' not in app_params.get('input_parameter_suite'):
                        options.append("rcs=t")
                else:
                    if not app_params.get('input_parameter_suite') \
                       or 'rcs=' not in app_params.get('input_parameter_suite'):
                        options.append("rcs=f")

            if app_params.get('min_id') and float(app_params['min_id']) != 0.0:
                if not app_params.get('input_parameter_suite') \
                   or 'min=' not in app_params.get('input_parameter_suite'):
                    options.append("minid={}".format(str(app_params['min_id'])))

            if app_params.get('speed_mode'):
                if app_params['speed_mode'] != 'default':
                    if 'slow' not in app_params.get('input_parameter_suite') \
                       and 'fast' not in app_params.get('input_parameter_suite'):
                        options.append(app_params['speed_mode'])

            if app_params.get('subfilter_thresh'):
                if not app_params.get('input_parameter_suite') \
                   or 'subfilter=' not in app_params.get('input_parameter_suite'):
                    options.append("subfilter={}".format(str(app_params['subfilter_thresh'])))

            if app_params.get('delfilter_thresh'):
                if not app_params.get('input_parameter_suite') \
                   or 'delfilter=' not in app_params.get('input_parameter_suite'):
                    options.append("delfilter={}".format(str(app_params['delfilter_thresh'])))

            # we always want covstats
            coverage_out_file = os.path.join(output_dir, str(assembly_i)+'-'+io_params['out_obj_name']+'-'+'covstats.txt')
            options.append('covstats={}'.format(coverage_out_file))
            

            # hard-code max threads for now
            max_threads = '4'
            options.append('t={}'.format(max_threads))

            # use pigz and unpigz for what are usually huge files
            options.append('pigz=t')
            options.append('unpigz=t')

            # enforce qual=33 if not given
            if app_params.get('qual_score_mode'):
                qual_score_mode = str(app_params['qual_score_mode'])
            else:
                qual_score_mode = '33'
            options.append('qin={}'.format(qual_score_mode))

            # add the memory requirement at the end
            options.append('-Xmx{}g'.format(mem))

            # finally, route stderr (a log file) to a file in the output dir
            options = options + ['2>', run_log]

            # enable multi assemblies later
            break

        return options

    def _validate_file_inputs(self, params, is_app):
        if is_app:
            method = 'BBMap App()'
            required_fields = ['in_assembly_refs', 'in_readslib_ref', 'workspace_name', 'out_obj_name']
            for r in required_fields:
                if r not in params:
                    raise ValueError('Error running '+method+': ' + r + ' parameter is required')
        else:
            method = 'BBMap Local()'
            required_fields = ['in_assembly_paths', 'in_readslib_path', 'out_obj_name']
            for r in required_fields:
                if r not in params:
                    raise ValueError('Error running '+method+': ' + r + ' parameter is required')

    def _save_output_to_kbase(self, io_params, app_params, output_dir, run_log, run_command):
        # TODO: insert the run_command into the output log
        #
        # read the output file list
        file_lookup = self._read_outputfile(os.path.join(output_dir, 'file-list.txt'))
        file_lookup2 = self._read_outputdir(output_dir)
        for k in file_lookup2:
            file_lookup[k] = file_lookup2[k]
        
        # return the contig coverage
        coverage = []
        if 'coverage_files' not in file_lookup:
            print('No coverage stats file found in output.  Not saving coverage.')
        else:
            [CONTIG_ID_I, Avg_fold_I, Length_I, Ref_GC_I, Covered_percent_I, Covered_bases_I, Plus_reads_I, Minus_reads_I, Read_GC_I, Median_fold_I, Std_Dev_I] = range(11)
            for file_name in file_lookup['coverage_files'].split(','):
                coverage_path = os.path.join(output_dir, file_name)
                this_coverage = {}
                with open (coverage_path, 'r') as cov_handle:
                    for cov_line in cov_handle.readlines():
                        #print ("COVERAGE: "+cov_line)  # DEBUG
                        cov_row = cov_line.rstrip().split()
                        if cov_row[CONTIG_ID_I] == '#ID':
                            continue
                        this_coverage[cov_row[CONTIG_ID_I]] = {}
                        this_coverage[cov_row[CONTIG_ID_I]]['avg_doc'] = float(cov_row[Avg_fold_I])
                        this_coverage[cov_row[CONTIG_ID_I]]['ctg_len'] = float(cov_row[Length_I])
                        this_coverage[cov_row[CONTIG_ID_I]]['cov_perc'] = float(cov_row[Covered_percent_I])
                        this_coverage[cov_row[CONTIG_ID_I]]['cov_bases'] = float(cov_row[Covered_bases_I])
                coverage.append(this_coverage)

        # get the read alignment stats
        read_align_stats = []
        this_read_align_stats = {}
        with open (run_log, 'r') as log_handle:
            for log_line in log_handle.readlines():
                if log_line.startswith('Genome:'):
                    if this_read_align_stats:
                        read_align_stats.append(this_read_align_stats)
                    this_read_align_stats = {}
                elif log_line.startswith('Reads Used:'):
                    this_read_align_stats['total_reads_cnt'] = float(log_line.split()[2])
                    this_read_align_stats['total_reads_bp']  = float(log_line.split()[3].replace('(',''))
                elif log_line.startswith('Mapped reads:'):
                    this_read_align_stats['mapped_reads_cnt'] = float(log_line.split()[2])
                elif log_line.startswith('Mapped bases:'):
                    this_read_align_stats['mapped_reads_bp'] = float(log_line.split()[2])
                elif log_line.startswith('Ref scaffolds:'):
                    this_read_align_stats['ref_scaf_num'] = float(log_line.split()[2])
                elif log_line.startswith('Ref bases:'):
                    this_read_align_stats['ref_scaf_bp'] = float(log_line.split()[2])
                elif log_line.startswith('Percent mapped:'):
                    this_read_align_stats['mapped_reads_perc'] = float(log_line.split()[2])
                elif log_line.startswith('Average coverage:'):
                    this_read_align_stats['avg_doc'] = float(log_line.split()[2])
                elif log_line.startswith('Percent scaffolds with any coverage:'):
                    this_read_align_stats['ref_scaf_num_hit_perc'] = float(log_line.split()[5])
                elif log_line.startswith('Percent of reference bases covered:'):
                    this_read_align_stats['ref_scaf_bases_hit_perc'] = float(log_line.split()[5])
        if this_read_align_stats:
            read_align_stats.append(this_read_align_stats)

            
        # save the new reads
        mapped_reads_ref = None
        unmapped_reads_ref = None
        objects_created = []
        if 'mapped_reads_files' not in file_lookup:
            print('No mapped reads fastq file found in output.  Not creating any mapped reads objects.')
        else:
            for file_name in file_lookup['mapped_reads_files'].split(','):
                mapped_reads_path = os.path.join(output_dir, file_name)
                mapped_reads_ref = upload_interleaved_reads(
                    self.callback_url,
                    mapped_reads_path,
                    io_params['workspace_name'],
                    file_name+'.reads',
                    io_params.get('in_readslib_ref'))
                objects_created.append({
                    'ref': mapped_reads_ref,
                    'description': 'Mapped reads library'
                })
        if 'unmapped_reads_files' not in file_lookup:
            print('No unmapped reads fastq file found in output.  Not creating any unmapped reads objects.')
        else:
            for file_name in file_lookup['unmapped_reads_files'].split(','):
                unmapped_reads_path = os.path.join(output_dir, file_name)
                unmapped_reads_ref = upload_interleaved_reads(
                    self.callback_url,
                    unmapped_reads_path,
                    io_params['workspace_name'],
                    file_name+'.reads',
                    io_params.get('in_readslib_ref'))
                objects_created.append({
                    'ref': unmapped_reads_ref,
                    'description': 'Unmapped reads library'
                })

        # build the HTML report
        html_zipped = self._build_html_report(io_params.get('in_readslib_ref'), output_dir, file_lookup, run_log)
        file_links = self._build_file_report(output_dir, run_log)
        # save the report
        report_params = {
            'message': '',
            'objects_created': objects_created,
            'direct_html_link_index': 0,
            'html_links': [html_zipped],
            'file_links': file_links,
            'report_object_name': 'bbtools_bbmap_report_' + str(uuid.uuid4()),
            'workspace_name': io_params['workspace_name']
        }

        kr = KBaseReport(self.callback_url)
        report_output = kr.create_extended_report(report_params)

        return {'report_name': report_output['name'],
                'report_ref': report_output['ref'],
                'run_command': run_command,
                'coverage': coverage,
                'read_align_stats': read_align_stats}

    def _build_file_report(self, output_dir, run_log):
        # list of files = start with everything that's unzipped (or not .fq.gz) in output_dir
        file_list = os.listdir(output_dir)
        result_file = os.path.join(output_dir, 'bbmap_report.zip')
        with zipfile.ZipFile(result_file, 'w', zipfile.ZIP_DEFLATED, allowZip64=True) as report_zip:
            for file_name in file_list:
                if file_name.lower().endswith('.gz') or file_name.lower().endswith('.fastq'):
                    continue
                zipped_file_name = file_name
                report_zip.write(os.path.join(output_dir, file_name), zipped_file_name)
        file_links = [{
            'path': result_file,
            'name': os.path.basename(result_file),
            'label': 'BBMap_report',
            'description': 'BBMap report files'
        }]
        return file_links

    def _read_outputdir(self, dir_path):
        filedata = {}
        multifile_data = {}
        multifile_data['coverage_files'] = []
        files = [f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))]
        for f in files:
            if f.endswith('-covstats.txt'):
                multifile_data['coverage_files'].append(f)
        filedata['coverage_files'] = ",".join(multifile_data['coverage_files'])
        return filedata

    def _read_outputfile(self, file_path):
        filedata = {}
        with open(file_path) as f:
            lines = [l.strip() for l in f.readlines()]
            for line in lines:
                if line:
                    if line.startswith('#'):
                        continue
                    tokens = line.split("\t", 1)
                    if len(tokens) != 2:
                        print('bad line in ' + file_path + ' output, skipping: ' + str(line))
                    filedata[tokens[0]] = tokens[1]
        return filedata

    def _read_bbmap_results_report(self, run_log):
        results_buf = []
        in_results = False
        with open(run_log) as run_log_handle:
            lines = [l.strip() for l in run_log_handle.readlines()]
            for line in lines:
                if '----   Results   ----' in line:
                    in_results = True
                    continue
                if not in_results:
                    continue
                results_buf.append(line)
        return results_buf
                

    def _build_html_report(self, reads_ref, output_dir, file_lookup, run_log):
        html_dir = os.path.join(self.scratch_dir, 'bbmap_report_' + self._timestamp)
        os.makedirs(html_dir)

        # note: we should use a real library, like yattag, to generate the HTML report here
        # this is just a quick hack to get one simple table parsed and displayed
        html = open(os.path.join(html_dir, 'BBMap_report.html'), 'w')
        html.write('<html><head><title>BBMap Report: ' + reads_ref + '</title></head>\n')
        html.write('<body>\n')

        bbmap_results_report_buf = self._read_bbmap_results_report(run_log)
        html.write('<blockquote><pre>\n')
        html.write("\n".join(bbmap_results_report_buf)+"\n")
        html.write('</pre></blockquote>\n')

        html.write('</body>\n')
        html.write('</html>')
        html.close()

        return pack_and_upload_folder(self.callback_url, html_dir, 'BBMap_report.html', 'Summarized report from BBMap')
